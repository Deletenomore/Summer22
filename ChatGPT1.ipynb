{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyK5Mav1LT7wTAJoMuSTmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0df666bc70aa44e8b2e62b29b4e63ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19b8d129600e48348ad8cf8b2ca7130d",
              "IPY_MODEL_9341bb5dee274824ad96bf535184cee6",
              "IPY_MODEL_82a2738e20084c32bb301227b62f6539"
            ],
            "layout": "IPY_MODEL_8dd8b85c78604f1c89bb0c84d7d83620"
          }
        },
        "19b8d129600e48348ad8cf8b2ca7130d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abfe354f91e84d65ad26c24536b4fb0a",
            "placeholder": "​",
            "style": "IPY_MODEL_9ca1ad7f75e74a5da63c7ae025b22b60",
            "value": "100%"
          }
        },
        "9341bb5dee274824ad96bf535184cee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f03aecb762f4072a63e4bc5f7d8a6d3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab93406b9ec6429cb1aad805cc6937e9",
            "value": 3
          }
        },
        "82a2738e20084c32bb301227b62f6539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4705e0200c2f415f9901059cffc1ee58",
            "placeholder": "​",
            "style": "IPY_MODEL_9be32bc554134543850e4a3632b73de7",
            "value": " 3/3 [00:00&lt;00:00,  6.01it/s]"
          }
        },
        "8dd8b85c78604f1c89bb0c84d7d83620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abfe354f91e84d65ad26c24536b4fb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca1ad7f75e74a5da63c7ae025b22b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f03aecb762f4072a63e4bc5f7d8a6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab93406b9ec6429cb1aad805cc6937e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4705e0200c2f415f9901059cffc1ee58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be32bc554134543850e4a3632b73de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74728504287943159d1af0802cb70af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95bd5ba011c64f71970cadc7a8a53aa7",
              "IPY_MODEL_4f0e1d71e9b84f8cb7ffac3a1b876860",
              "IPY_MODEL_b226e8062230470598c5398d2ae7ce73"
            ],
            "layout": "IPY_MODEL_bd204026b73a46d987c761be6a471da1"
          }
        },
        "95bd5ba011c64f71970cadc7a8a53aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e26a2d538347adba504c9973c47f8f",
            "placeholder": "​",
            "style": "IPY_MODEL_00afaec752d94d19829e989d96b75a04",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4f0e1d71e9b84f8cb7ffac3a1b876860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3eefb9982ab4061bfd5243afd91f8b5",
            "max": 1404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3525bb243db4287896a8a5920655684",
            "value": 1404
          }
        },
        "b226e8062230470598c5398d2ae7ce73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bb2b41e5fe14226aeaa031cdad8ce21",
            "placeholder": "​",
            "style": "IPY_MODEL_212fc5818304445db8a666f76c2b5844",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "bd204026b73a46d987c761be6a471da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e26a2d538347adba504c9973c47f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00afaec752d94d19829e989d96b75a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3eefb9982ab4061bfd5243afd91f8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3525bb243db4287896a8a5920655684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bb2b41e5fe14226aeaa031cdad8ce21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212fc5818304445db8a666f76c2b5844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a5acca2678648e48bf1ece485dda44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43d296f72a1446bb976b045099a7e12a",
              "IPY_MODEL_fd9fb6264a154677ae66c5720deeaeea",
              "IPY_MODEL_24130b3789304ac49c3fe267dd83ca3e"
            ],
            "layout": "IPY_MODEL_2a6e8f9f3d834f8f90904f05ad6b3af8"
          }
        },
        "43d296f72a1446bb976b045099a7e12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45236a1d5a464ad2ac7ec9df0540f305",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a6a135a955462891fa4cf149cfde8d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "fd9fb6264a154677ae66c5720deeaeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95dd570391d24827b08da2707277dc63",
            "max": 990402637,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_751fbfa0e2bb495e9714709abde45f9a",
            "value": 990402637
          }
        },
        "24130b3789304ac49c3fe267dd83ca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc5c89650ac4316a68d702282d27ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_32fa17f0dae0404685c6bfcff604d2be",
            "value": " 990M/990M [00:11&lt;00:00, 156MB/s]"
          }
        },
        "2a6e8f9f3d834f8f90904f05ad6b3af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45236a1d5a464ad2ac7ec9df0540f305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a6a135a955462891fa4cf149cfde8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95dd570391d24827b08da2707277dc63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751fbfa0e2bb495e9714709abde45f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efc5c89650ac4316a68d702282d27ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fa17f0dae0404685c6bfcff604d2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a4260cf2c345ac8cf82fd598619880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3375d4e5cf84a42819d35c54e6d578a",
              "IPY_MODEL_0fab11c0fbd24a78bc4ee34bb93784d7",
              "IPY_MODEL_071a7fed27c64315aaa0ae2f96c83ac2"
            ],
            "layout": "IPY_MODEL_de8ddef7e1304c30802faa833efca303"
          }
        },
        "e3375d4e5cf84a42819d35c54e6d578a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a61f67bd694d06917018b661aaa669",
            "placeholder": "​",
            "style": "IPY_MODEL_1d181f1b94694b8ca26e6c7db1e63c82",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "0fab11c0fbd24a78bc4ee34bb93784d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14495c30c9941c39dce40422a7c2633",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9136680414d4573807a64c928fcc9c0",
            "value": 147
          }
        },
        "071a7fed27c64315aaa0ae2f96c83ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e8296477794fb7b45defc5f5a2ed08",
            "placeholder": "​",
            "style": "IPY_MODEL_c44457ddb76f45f78117553569d4945a",
            "value": " 147/147 [00:00&lt;00:00, 7.17kB/s]"
          }
        },
        "de8ddef7e1304c30802faa833efca303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a61f67bd694d06917018b661aaa669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d181f1b94694b8ca26e6c7db1e63c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a14495c30c9941c39dce40422a7c2633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9136680414d4573807a64c928fcc9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7e8296477794fb7b45defc5f5a2ed08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c44457ddb76f45f78117553569d4945a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ef406ecf97944b3a3e0d9679663136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5459294f4e3a42ccb587e1441f99fd8f",
              "IPY_MODEL_34d02bfb5ddb46a9b6b0cbfe206dcd3f",
              "IPY_MODEL_5ceb7913205b4cba9fc4b68774c91cac"
            ],
            "layout": "IPY_MODEL_752245abf31c47718b6d3037f5efd98c"
          }
        },
        "5459294f4e3a42ccb587e1441f99fd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf507bfa32ba4475a45763fd08d6bfd0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b26c9af9f7945749812129230199be8",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "34d02bfb5ddb46a9b6b0cbfe206dcd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bf4323f3bd3440da80ea72ca9e1a3f0",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cc14b2c07584a9bada303fe3eee1807",
            "value": 2537
          }
        },
        "5ceb7913205b4cba9fc4b68774c91cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b7945ed83848538c47ce3beb73dafa",
            "placeholder": "​",
            "style": "IPY_MODEL_735cdb86ced94c64ab271638fe235029",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "752245abf31c47718b6d3037f5efd98c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf507bfa32ba4475a45763fd08d6bfd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b26c9af9f7945749812129230199be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf4323f3bd3440da80ea72ca9e1a3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc14b2c07584a9bada303fe3eee1807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b7945ed83848538c47ce3beb73dafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735cdb86ced94c64ab271638fe235029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10fba809712849edbe29d77e9e7df759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00717eeb5ede4da5b57c91a5c4b1ab49",
              "IPY_MODEL_be3e6cd980b74f8792ece8a43048939f",
              "IPY_MODEL_de60efcd5e2944a6873264ed0e177ec8"
            ],
            "layout": "IPY_MODEL_9fdb821fe7854a0fb29899b53efd95d9"
          }
        },
        "00717eeb5ede4da5b57c91a5c4b1ab49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dcc30bd4ced4b828560c492c9ccd517",
            "placeholder": "​",
            "style": "IPY_MODEL_51a6b06b0fdd4f6a9410a3fc6cefb64b",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "be3e6cd980b74f8792ece8a43048939f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e182d8d40d4b5aa91b1df37ad0f11a",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e4cf3227f1a430d9c2a26356db54ee7",
            "value": 791656
          }
        },
        "de60efcd5e2944a6873264ed0e177ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639c6187a9fb43e6bffeaef36c6914c2",
            "placeholder": "​",
            "style": "IPY_MODEL_36449d7c0c9042ebb3aa48fe678b06d3",
            "value": " 792k/792k [00:00&lt;00:00, 3.40MB/s]"
          }
        },
        "9fdb821fe7854a0fb29899b53efd95d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcc30bd4ced4b828560c492c9ccd517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a6b06b0fdd4f6a9410a3fc6cefb64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e182d8d40d4b5aa91b1df37ad0f11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4cf3227f1a430d9c2a26356db54ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "639c6187a9fb43e6bffeaef36c6914c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36449d7c0c9042ebb3aa48fe678b06d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422bd68570ff4d0090dd539c844f3067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efd2f499a0204fb7bdb1e21053f29ec2",
              "IPY_MODEL_626c4e095c014ab2a3069785ed48ed89",
              "IPY_MODEL_8abc9cf2fe7b4d67a764cf384eb3023f"
            ],
            "layout": "IPY_MODEL_c5e5b81c4fc8413b9f22a256125a50c9"
          }
        },
        "efd2f499a0204fb7bdb1e21053f29ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5468bf4bad944dd385347e6b74b6e39a",
            "placeholder": "​",
            "style": "IPY_MODEL_880bf1f219bd4e8ea1ff9e999ee5ba77",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "626c4e095c014ab2a3069785ed48ed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc46e660176a411ab0a25451cd4efbed",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae1e0240bcde4f5dbecec3f06d3d0a91",
            "value": 2424064
          }
        },
        "8abc9cf2fe7b4d67a764cf384eb3023f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6563aec182f34208ab02f1b30bb8f24a",
            "placeholder": "​",
            "style": "IPY_MODEL_c48fc3a850bc4cdf8be0f85671380a87",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 23.4MB/s]"
          }
        },
        "c5e5b81c4fc8413b9f22a256125a50c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5468bf4bad944dd385347e6b74b6e39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880bf1f219bd4e8ea1ff9e999ee5ba77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc46e660176a411ab0a25451cd4efbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1e0240bcde4f5dbecec3f06d3d0a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6563aec182f34208ab02f1b30bb8f24a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48fc3a850bc4cdf8be0f85671380a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6daeed7bf68452da136e4eec441e330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49f04175a2154b02ab12ed2dd24b1f92",
              "IPY_MODEL_b457e670d8864e9797a11282efe05066",
              "IPY_MODEL_9f2c666cbef1445a8fa3a773bbbf6819"
            ],
            "layout": "IPY_MODEL_06b6bf513e094192abdac9f04969ef09"
          }
        },
        "49f04175a2154b02ab12ed2dd24b1f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ceae294d904014b8c16e158460c843",
            "placeholder": "​",
            "style": "IPY_MODEL_2da55c81889c41d09c32977016748b9d",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b457e670d8864e9797a11282efe05066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ba5dad51a4446c91c08e020ef819cf",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_985d3287c9994032bfdcbb9e31434156",
            "value": 2201
          }
        },
        "9f2c666cbef1445a8fa3a773bbbf6819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ddc4fb9d68747eea8ed4b3edbc4055c",
            "placeholder": "​",
            "style": "IPY_MODEL_0702a529370f4d08a6d03c2bd92090b2",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 75.0kB/s]"
          }
        },
        "06b6bf513e094192abdac9f04969ef09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ceae294d904014b8c16e158460c843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da55c81889c41d09c32977016748b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03ba5dad51a4446c91c08e020ef819cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "985d3287c9994032bfdcbb9e31434156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ddc4fb9d68747eea8ed4b3edbc4055c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0702a529370f4d08a6d03c2bd92090b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everestso/Summer22/blob/main/ChatGPT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJODhKhVkRqd",
        "outputId": "2bb4f08e-56da-4bab-cbd4-6d2d823e50a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/73.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v_igqKotPwx",
        "outputId": "fc7b278b-0aff-4538-ad6d-1609e3282c9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/\n",
        "f = open(\"ChatGptApi.txt\")\n",
        "s = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnQcJJOBvYkp",
        "outputId": "6c974880-c6d9-45cd-8e95-d7b07abfb8cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uvYVnu0qkLpF"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "openai.api_key  =  s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "0peLUIYDl9ok"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "Describe in 100 words the charismatic movement within\n",
        "catholic church including charasmatic mass. Further provide potential\n",
        "for promoting growth in Europe.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print('\\n'.join(textwrap.wrap(response,70)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EPYng8qMYZ_",
        "outputId": "e85e0549-ad79-4625-d831-b0f905fce110"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The charismatic movement within the Catholic Church is a renewal\n",
            "movement that emphasizes the presence and work of the Holy Spirit in\n",
            "the lives of believers. It emerged in the late 1960s and gained\n",
            "momentum in the 1970s, bringing a more vibrant and expressive form of\n",
            "worship to the Church. The movement emphasizes spiritual gifts such as\n",
            "speaking in tongues, prophecy, and healing, and seeks to foster a\n",
            "personal and experiential relationship with God.  The charismatic mass\n",
            "is a form of worship within the Catholic Church that incorporates\n",
            "charismatic elements, such as lively music, spontaneous prayer, and an\n",
            "emphasis on the Holy Spirit's presence. It often includes moments of\n",
            "praise and worship, where participants may raise their hands, clap, or\n",
            "even dance.  In terms of promoting growth in Europe, the charismatic\n",
            "movement has the potential to attract and engage younger generations\n",
            "who may be seeking a more experiential and emotionally connected form\n",
            "of worship. The charismatic mass, with its vibrant and participatory\n",
            "nature, can create a sense of community and excitement that may appeal\n",
            "to those who feel disconnected from traditional forms of worship.\n",
            "Additionally, the movement's emphasis on personal spiritual\n",
            "experiences and the Holy Spirit's work can provide a sense of\n",
            "empowerment and relevance to individuals seeking a deeper connection\n",
            "with their faith.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=f\"\"\"\n",
        "What is the source and meaning of the following quote, \"If your not first, your last.\"\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print('\\n'.join(textwrap.wrap(response,70)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwfGAjIRvdQY",
        "outputId": "04552a86-53fa-471f-ea08-f0a4a2dca37f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quote \"If you're not first, you're last\" is a line from the\n",
            "character Ricky Bobby, played by Will Ferrell, in the 2006 comedy film\n",
            "\"Talladega Nights: The Ballad of Ricky Bobby.\" In the movie, Ricky\n",
            "Bobby is a race car driver who believes that winning is everything and\n",
            "that coming in any position other than first place is equivalent to\n",
            "being a loser. The quote is often used humorously to emphasize the\n",
            "extreme competitiveness and obsession with winning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " Corey Lynch, Kamelia Aryafar, and Josh Attenberg. 2016. Images Don't Lie:\n",
        " Transferring Deep Visual Semantic Features to Large-Scale Multimodal Learning to Rank.\n",
        " In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16).\n",
        " Association for Computing Machinery, New York, NY, USA, 541–548.\n",
        " https://doi.org/10.1145/2939672.2939728\n",
        "\"\"\"\n",
        "\n",
        "text = f\"\"\"\n",
        "Search is at the heart of modern e-commerce. As a result, the task  \\\n",
        "of ranking search results automatically (learning to rank) is a multibillion  \\\n",
        "dollar machine learning problem. Traditional models optimize  \\\n",
        "over a few hand-constructed features based on the item’s text.  \\\n",
        "In this paper, we introduce a multimodal learning to rank model that  \\\n",
        "combines these traditional features with visual semantic features  \\\n",
        "transferred from a deep convolutional neural network. In a large  \\\n",
        "scale experiment using data from the online marketplace Etsy 1,  \\\n",
        "we verify that moving to a multimodal representation significantly  \\\n",
        "improves ranking quality. We show how image features can capture  \\\n",
        "fine-grained style information not available in a text-only representation.  \\\n",
        "In addition, we show concrete examples of how image  \\\n",
        "information can successfully disentangle pairs of highly different  \\\n",
        "items that are ranked similarly by a text-only model.  \\\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"\\n\".join(textwrap.wrap(response,70)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkupPHwMmAjz",
        "outputId": "e16816d7-25eb-46b8-8d07-a2f0b11eec34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text discusses the importance of search in e-commerce and the use\n",
            "of a multimodal learning to rank model that combines traditional\n",
            "features with visual semantic features to improve ranking quality in a\n",
            "large-scale experiment using data from Etsy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.austinchronicle.com/events/film/2022-12-23/whitney-houston-i-wanna-dance-with-somebody/\n",
        "# ★½  (-4)\n",
        "text = f\"\"\"\n",
        "Whitney Houston was an icon, a legend of the music industry and a breathtaking pop idol who cranked out hit after hit, shattering records that previously the Beatles and Elvis held. Houston had enormous range and depth, yet the film about this larger-than-life superstar is somehow one of the flattest, cheapest, and most underwhelming music biopics to ever land on the silver screen.  \\\n",
        "Directed by Kasi Lemmons (Harriet, Eve’s Bayou), Whitney Houston: I Wanna Dance With Somebody somehow manages to make the life of Houston so painfully dull and thin. Just as the heat begins to rise, the film skips ahead, or around, orbiting the chance to dig deeper, to offer a more meaningful glimpse into the pop star’s history. Anthony McCarten’s script coasts, breezing through Houston’s life with a coolness that is anticlimactic. Father issues, her divorce, queer identity struggles, and addiction are danced around, never really creating a deep impact on an emotional level. When the bombastic moments like Houston’s historic performances in a newly post-apartheid South Africa arrive, they do so with a whimper, with tacky CGI stadiums that bring a tepid energy to the watered-down performances.  \\\n",
        "There’s no bite to Naomi Ackie’s performance, and perhaps that is because she’s not given anything worth chewing on. Even the clothes they drape her in feel cheap and poorly made. One of the film’s greatest injustices is that, after Ackie’s “big” performance of the iconic “I Have Nothing” medley Houston sang at the 1994 American Music Awards, the live broadcast is immediately shown in the credits, highlighting the stark difference in quality. The movie replaces her lush velvet caped black dress with a fast-fashion, wrinkled gown that’s bejeweled with clunky plastic gems. This fizzled ending echoes the sentiment of the entire film, a watered-down TV-soap approach to its dramatic subject.  \\\n",
        "Whitney Houston: I Wanna Dance With Somebody is like the SparkNotes of her life, a smattering of collected moments that feel hollow. The film retroactively makes Baz Luhrmann’s Elvis look like a masterpiece for actually trying to be bedazzling and insane, because Whitney Houston: I Wanna Dance With Somebody is so stale it might as well have been shoved directly onto a streaming platform to wither away forgotten – unlike Houston’s discography, which will be remembered for decades to come.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Evaluate the sentiment of the following quote between \"```\" \\\n",
        "from negative 10 to positive 10 and output for each just the numeric value, \\\n",
        "do not include any additional text, just the numeric value:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"\\n\".join(textwrap.wrap(response,70)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pntYAHByTSP",
        "outputId": "e170e91a-23e4-498b-a98f-e17e59e772e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.smh.com.au/culture/movies/all-the-boxing-day-movies-reviewed-what-should-you-see-or-skip-20221220-p5c7t1.html\n",
        "# Whitney Houston: I Wanna Dance with Somebody ★★★½  (+4)\n",
        "text = f\"\"\"\n",
        "What more is there to say about Whitney Houston, whose brilliant career, drug-taking and premature death has been hashed over exhaustively on screen and in the tabloids?  \\\n",
        "I Wanna Dance with Somebody tackles that question by taking her story back to the music. It’s written by New Zealander Anthony McCarten, whose screenplay for Bohemian Rhapsody didn’t dilute the tragedies in Freddie Mercury’s short life while still managing to evoke the exhilaration to be had from Queen’s greatest concerts.  \\\n",
        "It took a delicate touch and other rock stars haven’t been as fortunate. While Rocketman was just as exuberant in doing justice to Elton John as a performer, the Aretha Franklin biopic Respect (2021) became more depressing as it went on. The United States vs. Billie Holiday, also released last year, was the same. It was powerful but it was no celebration. Then there was Baz Luhrmann’s Elvis, which was more glitz than heart, clouded by the decision to tell the tale from the venal viewpoint of Presley’s manager, Colonel Tom Parker.  \\\n",
        "Members of Houston’s family were interviewed at length for a documentary four years ago. But for this film, also produced with the family’s co-operation, director Kasi Lemmons made extensive use of the singer’s original recordings, including those laid down en route to the final versions. It allowed star Naomi Ackie to take Houston’s false starts, double takes and spontaneous comments as prompts in shaping her performance. Although she was filmed singing, her voice was replaced by Houston’s.  \\\n",
        "She does well, catching the contradictions in Houston’s character – the naivete, the fear of failure, the rebellious streak and its effect on her religious convictions. But physically, Ackie bears only a superficial resemblance to the singer. With Houston’s image still so fresh in the memory, this is a distraction.  \\\n",
        "The script is impressionistic in style, covering a lot of ground by being selective and using Houston’s songs to drive the narrative. Much is made of her relationship with the record company chief Clive Davis (one of the film’s producers), who discovered Houston and helped her choose songs for her albums. He’s played by a wryly urbane Stanley Tucci, giving us a character whose iron fist is well covered in velvet. Appalled when Houston takes up smoking, he looks sadly at her as she lights up, remarking that it’s like watching a Stradivarius being left out in the rain.  \\\n",
        "The film falls a little short of its claim to be warts-and-all, condensing the low points in Houston’s turbulent marriage to Bobby Brown (Ashton Sanders), but it doesn’t hold back in dealing with her father’s financial mismanagement. Nor does it underplay the importance of her enduring friendship with her former lover, Robyn Crawford – played with a lot of verve by Nafessa Williams.  \\\n",
        "And while it leaves her death off-screen, preferring to go out with the show-stopping medley she delivered at the 1994 American Music Awards, I’m not complaining. Sandra Hall\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Evaluate the sentiment of the following quote between \"```\" \\\n",
        "from negative 10 to positive 10 and output for each just the numeric value, \\\n",
        "do not include any additional text, just the numeric value:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "kz51EdyezVp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375cdf3f-0c1d-488b-8fd4-ef4aac5cd561"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "January 1, 1863\n",
        "\n",
        "A Transcription\n",
        "\n",
        "By the President of the United States of America:\n",
        "\n",
        "A Proclamation.\n",
        "\n",
        "Whereas, on the twenty-second day of September, in the year of our Lord one thousand eight hundred and sixty-two, a proclamation was issued by the President of the United States, containing, among other things, the following, to wit:\n",
        "\n",
        "\"That on the first day of January, in the year of our Lord one thousand eight hundred and sixty-three, all persons held as slaves within any State or designated part of a State, the people whereof shall then be in rebellion against the United States, shall be then, thenceforward, and forever free; and the Executive Government of the United States, including the military and naval authority thereof, will recognize and maintain the freedom of such persons, and will do no act or acts to repress such persons, or any of them, in any efforts they may make for their actual freedom.\n",
        "\n",
        "\"That the Executive will, on the first day of January aforesaid, by proclamation, designate the States and parts of States, if any, in which the people thereof, respectively, shall then be in rebellion against the United States; and the fact that any State, or the people thereof, shall on that day be, in good faith, represented in the Congress of the United States by members chosen thereto at elections wherein a majority of the qualified voters of such State shall have participated, shall, in the absence of strong countervailing testimony, be deemed conclusive evidence that such State, and the people thereof, are not then in rebellion against the United States.\"\n",
        "\n",
        "Now, therefore I, Abraham Lincoln, President of the United States, by virtue of the power in me vested as Commander-in-Chief, of the Army and Navy of the United States in time of actual armed rebellion against the authority and government of the United States, and as a fit and necessary war measure for suppressing said rebellion, do, on this first day of January, in the year of our Lord one thousand eight hundred and sixty-three, and in accordance with my purpose so to do publicly proclaimed for the full period of one hundred days, from the day first above mentioned, order and designate as the States and parts of States wherein the people thereof respectively, are this day in rebellion against the United States, the following, to wit:\n",
        "\n",
        "Arkansas, Texas, Louisiana, (except the Parishes of St. Bernard, Plaquemines, Jefferson, St. John, St. Charles, St. James Ascension, Assumption, Terrebonne, Lafourche, St. Mary, St. Martin, and Orleans, including the City of New Orleans) Mississippi, Alabama, Florida, Georgia, South Carolina, North Carolina, and Virginia, (except the forty-eight counties designated as West Virginia, and also the counties of Berkley, Accomac, Northampton, Elizabeth City, York, Princess Ann, and Norfolk, including the cities of Norfolk and Portsmouth[)], and which excepted parts, are for the present, left precisely as if this proclamation were not issued.\n",
        "\n",
        "And by virtue of the power, and for the purpose aforesaid, I do order and declare that all persons held as slaves within said designated States, and parts of States, are, and henceforward shall be free; and that the Executive government of the United States, including the military and naval authorities thereof, will recognize and maintain the freedom of said persons.\n",
        "\n",
        "And I hereby enjoin upon the people so declared to be free to abstain from all violence, unless in necessary self-defence; and I recommend to them that, in all cases when allowed, they labor faithfully for reasonable wages.\n",
        "\n",
        "And I further declare and make known, that such persons of suitable condition, will be received into the armed service of the United States to garrison forts, positions, stations, and other places, and to man vessels of all sorts in said service.\n",
        "\n",
        "And upon this act, sincerely believed to be an act of justice, warranted by the Constitution, upon military necessity, I invoke the considerate judgment of mankind, and the gracious favor of Almighty God.\n",
        "\n",
        "In witness whereof, I have hereunto set my hand and caused the seal of the United States to be affixed.\n",
        "\n",
        "Done at the City of Washington, this first day of January, in the year of our Lord one thousand eight hundred and sixty three, and of the Independence of the United States of America the eighty-seventh.\n",
        "\n",
        "By the President: ABRAHAM LINCOLN\n",
        "WILLIAM H. SEWARD, Secretary of State.\n",
        "\n",
        "\"\"\"\n",
        "print(\"\\n\".join(textwrap.wrap(text,70)))"
      ],
      "metadata": {
        "id": "aKSmpGH-Ah0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8d542d-ed95-4ce6-c847-9aa27fdfa5ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " January 1, 1863  A Transcription  By the President of the United\n",
            "States of America:  A Proclamation.  Whereas, on the twenty-second day\n",
            "of September, in the year of our Lord one thousand eight hundred and\n",
            "sixty-two, a proclamation was issued by the President of the United\n",
            "States, containing, among other things, the following, to wit:  \"That\n",
            "on the first day of January, in the year of our Lord one thousand\n",
            "eight hundred and sixty-three, all persons held as slaves within any\n",
            "State or designated part of a State, the people whereof shall then be\n",
            "in rebellion against the United States, shall be then, thenceforward,\n",
            "and forever free; and the Executive Government of the United States,\n",
            "including the military and naval authority thereof, will recognize and\n",
            "maintain the freedom of such persons, and will do no act or acts to\n",
            "repress such persons, or any of them, in any efforts they may make for\n",
            "their actual freedom.  \"That the Executive will, on the first day of\n",
            "January aforesaid, by proclamation, designate the States and parts of\n",
            "States, if any, in which the people thereof, respectively, shall then\n",
            "be in rebellion against the United States; and the fact that any\n",
            "State, or the people thereof, shall on that day be, in good faith,\n",
            "represented in the Congress of the United States by members chosen\n",
            "thereto at elections wherein a majority of the qualified voters of\n",
            "such State shall have participated, shall, in the absence of strong\n",
            "countervailing testimony, be deemed conclusive evidence that such\n",
            "State, and the people thereof, are not then in rebellion against the\n",
            "United States.\"  Now, therefore I, Abraham Lincoln, President of the\n",
            "United States, by virtue of the power in me vested as Commander-in-\n",
            "Chief, of the Army and Navy of the United States in time of actual\n",
            "armed rebellion against the authority and government of the United\n",
            "States, and as a fit and necessary war measure for suppressing said\n",
            "rebellion, do, on this first day of January, in the year of our Lord\n",
            "one thousand eight hundred and sixty-three, and in accordance with my\n",
            "purpose so to do publicly proclaimed for the full period of one\n",
            "hundred days, from the day first above mentioned, order and designate\n",
            "as the States and parts of States wherein the people thereof\n",
            "respectively, are this day in rebellion against the United States, the\n",
            "following, to wit:  Arkansas, Texas, Louisiana, (except the Parishes\n",
            "of St. Bernard, Plaquemines, Jefferson, St. John, St. Charles, St.\n",
            "James Ascension, Assumption, Terrebonne, Lafourche, St. Mary, St.\n",
            "Martin, and Orleans, including the City of New Orleans) Mississippi,\n",
            "Alabama, Florida, Georgia, South Carolina, North Carolina, and\n",
            "Virginia, (except the forty-eight counties designated as West\n",
            "Virginia, and also the counties of Berkley, Accomac, Northampton,\n",
            "Elizabeth City, York, Princess Ann, and Norfolk, including the cities\n",
            "of Norfolk and Portsmouth[)], and which excepted parts, are for the\n",
            "present, left precisely as if this proclamation were not issued.  And\n",
            "by virtue of the power, and for the purpose aforesaid, I do order and\n",
            "declare that all persons held as slaves within said designated States,\n",
            "and parts of States, are, and henceforward shall be free; and that the\n",
            "Executive government of the United States, including the military and\n",
            "naval authorities thereof, will recognize and maintain the freedom of\n",
            "said persons.  And I hereby enjoin upon the people so declared to be\n",
            "free to abstain from all violence, unless in necessary self-defence;\n",
            "and I recommend to them that, in all cases when allowed, they labor\n",
            "faithfully for reasonable wages.  And I further declare and make\n",
            "known, that such persons of suitable condition, will be received into\n",
            "the armed service of the United States to garrison forts, positions,\n",
            "stations, and other places, and to man vessels of all sorts in said\n",
            "service.  And upon this act, sincerely believed to be an act of\n",
            "justice, warranted by the Constitution, upon military necessity, I\n",
            "invoke the considerate judgment of mankind, and the gracious favor of\n",
            "Almighty God.  In witness whereof, I have hereunto set my hand and\n",
            "caused the seal of the United States to be affixed.  Done at the City\n",
            "of Washington, this first day of January, in the year of our Lord one\n",
            "thousand eight hundred and sixty three, and of the Independence of the\n",
            "United States of America the eighty-seventh.  By the President:\n",
            "ABRAHAM LINCOLN WILLIAM H. SEWARD, Secretary of State.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize in 30 words the following book between \"```\" \\\n",
        ":\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(\"\\n\".join(textwrap.wrap(response,70)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8lkn34l9b63",
        "outputId": "658521d2-b198-4aee-9e0d-dab3c5743a1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This book is a transcription of Abraham Lincoln's proclamation on\n",
            "January 1, 1863, declaring that all slaves in rebellious states are to\n",
            "be freed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Pablo Picasso: Modern Artist, Master Innovator\n",
        "Pablo Picasso (1881–1973), the Spanish-born, Paris-based painter, sculptor, draftsman, printmaker, decorative artist, and writer, influenced the course of 20th-century art with almost unmatched magnitude. His passionate and often provocative life, his unfettered embrace of experimentation, and his drive for re-invention fed into his prolific production of works, upending notions of what art was supposed to look like.\n",
        "\n",
        "Picasso’s numerous inspirations ranged from history, politics, and current events to the work of fellow artists, to the world outside of his studio. In his dynamic body of work, such opposites as intellect and emotions, forms of classicism and expressionism, and the conscious and the unconscious simultaneously clashed and coalesced.\n",
        "\n",
        "He was known for his fascination with so-called “Primitive” art, a term Europeans used when referring to African masks and statuary, which for Picasso also encompassed ancient carvings from the Iberian Peninsula, the landmass that eventually would be divided into present-day Spain, Andorra, and Portugal. The blocky, pared-down forms and forceful, angular planes of this art ignited the artist’s imagination. Its striking shapes and contours made their way into his own compositions and contributed to his radical restructuring of the formal characteristics and visual impact of the work of art. Together with fellow artist Georges Braque, Picasso pioneered Cubism, a visual language of geometric planes and compressed space that splintered subjects—like the human figure, a landscape, or a still life scene—into multifaceted pieces, causing them to appear partially abstracted, flattened, and fragmented, as if reflected in a shattered mirror.\n",
        "\n",
        "Picasso’s influence stretched well beyond Cubism. Over the course of his career, he produced works that significantly shaped Surrealism and Expressionism, not to mention the ongoing resonance of his legacy still felt by artists working today.\n",
        "\n",
        "Cubism\n",
        "Following their 1907 meeting in Paris, artists Pablo Picasso and Georges Braque pioneered the Cubist style, a new vision for a new century that inspired paintings that were initially ridiculed by critics for consisting of “little cubes.” Often painting side-by-side in their Montmartre, Paris, studios, the artists developed a visual language of geometric planes and compressed space that rejected the conventions of perspective and representation. Cubist works challenged viewers to understand a subject broken down into its geometrical components and often represented from several angles at once. Traditional subjects like nude figures, landscapes, and still lifes were reinvented as increasingly fragmented compositions by Picasso, Braque, and other artists working in and around the French capital.\n",
        "\n",
        "Cubists abstracted from real life to make their work, but most often maintained small identifiable clues to a realistic figure, whether a woman or a violin. The artists adopted a neutral palette of browns and blacks, intending the viewer to focus on the geometric composition rather than the color. Cubism marks a pioneering moment in the history of art—one that ended when many of its leading practitioners, Braque among them, enlisted to fight in World War I.\n",
        "\"\"\"\n",
        "print(\"\\n\".join(textwrap.wrap(text,70)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C27tIfHxSfKy",
        "outputId": "f4a0f67f-f5ad-488c-cbc6-a1680ccdf73d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pablo Picasso: Modern Artist, Master Innovator Pablo Picasso\n",
            "(1881–1973), the Spanish-born, Paris-based painter, sculptor,\n",
            "draftsman, printmaker, decorative artist, and writer, influenced the\n",
            "course of 20th-century art with almost unmatched magnitude. His\n",
            "passionate and often provocative life, his unfettered embrace of\n",
            "experimentation, and his drive for re-invention fed into his prolific\n",
            "production of works, upending notions of what art was supposed to look\n",
            "like.  Picasso’s numerous inspirations ranged from history, politics,\n",
            "and current events to the work of fellow artists, to the world outside\n",
            "of his studio. In his dynamic body of work, such opposites as\n",
            "intellect and emotions, forms of classicism and expressionism, and the\n",
            "conscious and the unconscious simultaneously clashed and coalesced.\n",
            "He was known for his fascination with so-called “Primitive” art, a\n",
            "term Europeans used when referring to African masks and statuary,\n",
            "which for Picasso also encompassed ancient carvings from the Iberian\n",
            "Peninsula, the landmass that eventually would be divided into present-\n",
            "day Spain, Andorra, and Portugal. The blocky, pared-down forms and\n",
            "forceful, angular planes of this art ignited the artist’s imagination.\n",
            "Its striking shapes and contours made their way into his own\n",
            "compositions and contributed to his radical restructuring of the\n",
            "formal characteristics and visual impact of the work of art. Together\n",
            "with fellow artist Georges Braque, Picasso pioneered Cubism, a visual\n",
            "language of geometric planes and compressed space that splintered\n",
            "subjects—like the human figure, a landscape, or a still life\n",
            "scene—into multifaceted pieces, causing them to appear partially\n",
            "abstracted, flattened, and fragmented, as if reflected in a shattered\n",
            "mirror.  Picasso’s influence stretched well beyond Cubism. Over the\n",
            "course of his career, he produced works that significantly shaped\n",
            "Surrealism and Expressionism, not to mention the ongoing resonance of\n",
            "his legacy still felt by artists working today.  Cubism Following\n",
            "their 1907 meeting in Paris, artists Pablo Picasso and Georges Braque\n",
            "pioneered the Cubist style, a new vision for a new century that\n",
            "inspired paintings that were initially ridiculed by critics for\n",
            "consisting of “little cubes.” Often painting side-by-side in their\n",
            "Montmartre, Paris, studios, the artists developed a visual language of\n",
            "geometric planes and compressed space that rejected the conventions of\n",
            "perspective and representation. Cubist works challenged viewers to\n",
            "understand a subject broken down into its geometrical components and\n",
            "often represented from several angles at once. Traditional subjects\n",
            "like nude figures, landscapes, and still lifes were reinvented as\n",
            "increasingly fragmented compositions by Picasso, Braque, and other\n",
            "artists working in and around the French capital.  Cubists abstracted\n",
            "from real life to make their work, but most often maintained small\n",
            "identifiable clues to a realistic figure, whether a woman or a violin.\n",
            "The artists adopted a neutral palette of browns and blacks, intending\n",
            "the viewer to focus on the geometric composition rather than the\n",
            "color. Cubism marks a pioneering moment in the history of art—one that\n",
            "ended when many of its leading practitioners, Braque among them,\n",
            "enlisted to fight in World War I.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = f\"What art movement did Pablo Picasso help pioneer?\"\n",
        "question2 = f\"Describe the visual language of Cubism. Support your description with details from the text.\"\n",
        "question3 = f\"What is the main idea of this text?\"\n",
        "question4 = f\"How did Picasso challenge ideas about 'what art was supposed to look like'? Give at least two details from the text to support your answer.\"\n",
        "prompt = f\"\"\"\n",
        "Given the following passage between \"```\" \\\n",
        ":\n",
        "```{text}```\n",
        "\n",
        "answer the following questions between \"```\" \\\n",
        "separate answers to each question with '$$$' \\\n",
        "and add '\\n' to keep lines shorter than 40 characters.\n",
        "'''{question1}'''\n",
        "'''{question2}'''\n",
        "'''{question3}'''\n",
        "'''{question4}'''\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = get_completion(prompt)"
      ],
      "metadata": {
        "id": "uDWwrWAuSmIp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer1, answer2, answer3, answer4, _=response.split('$$$')\n",
        "print (f\"\\nQ1: {question1}\")\n",
        "print(\"\\n\".join(textwrap.wrap(answer1,70)))\n",
        "print (f\"\\nQ2: {question2}\")\n",
        "print(\"\\n\".join(textwrap.wrap(answer2,70)))\n",
        "print (f\"\\nQ3: {question3}\")\n",
        "print(\"\\n\".join(textwrap.wrap(answer3,70)))\n",
        "print (f\"\\nQ4: {question4}\")\n",
        "print(\"\\n\".join(textwrap.wrap(answer4,70)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLO4cZ3HVRnl",
        "outputId": "533b56b5-8cb9-4053-c490-cae3989c509b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q1: What art movement did Pablo Picasso help pioneer?\n",
            "'''What art movement did Pablo Picasso help pioneer?''' Cubism\n",
            "\n",
            "Q2: Describe the visual language of Cubism. Support your description with details from the text.\n",
            "  '''Describe the visual language of Cubism. Support your description\n",
            "with details from the text.''' Cubism is a visual language of\n",
            "geometric planes and compressed space that splintered subjects into\n",
            "multifaceted pieces, causing them to appear partially abstracted,\n",
            "flattened, and fragmented. It rejected the conventions of perspective\n",
            "and representation and often represented subjects from multiple angles\n",
            "at once. The artists adopted a neutral palette of browns and blacks to\n",
            "focus on the geometric composition rather than the color.\n",
            "\n",
            "Q3: What is the main idea of this text?\n",
            "  '''What is the main idea of this text?''' The main idea of this text\n",
            "is that Pablo Picasso, through his innovative and prolific body of\n",
            "work, influenced the course of 20th-century art with almost unmatched\n",
            "magnitude. His passion for experimentation and drive for re-invention\n",
            "challenged traditional notions of art and led to the development of\n",
            "movements such as Cubism, Surrealism, and Expressionism. His influence\n",
            "continues to resonate with artists today.\n",
            "\n",
            "Q4: How did Picasso challenge ideas about 'what art was supposed to look like'? Give at least two details from the text to support your answer.\n",
            "  '''How did Picasso challenge ideas about 'what art was supposed to\n",
            "look like'? Give at least two details from the text to support your\n",
            "answer.''' Picasso challenged ideas about 'what art was supposed to\n",
            "look like' by: 1. Embracing experimentation and reinvention, which\n",
            "upended traditional notions of art. 2. Pioneering Cubism, a visual\n",
            "language that shattered the traditional representation of subjects and\n",
            "fragmented them into geometric planes, causing them to appear\n",
            "partially abstracted and flattened. This challenged the conventions of\n",
            "perspective and representation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/GPT-4\"\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# find all the text on the page\n",
        "text = soup.get_text()\n",
        "\n",
        "# find the content div\n",
        "content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
        "\n",
        "# remove unwanted elements from div\n",
        "unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n",
        "for tag in unwanted_tags:\n",
        "    for match in content_div.findAll(tag):\n",
        "        match.extract()\n",
        "\n",
        "print(content_div.get_text())"
      ],
      "metadata": {
        "id": "iD22wlMkUFNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3e5bdd-ff0b-4ac2-feb9-00f947dc0d0d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023 text-generating language model\n",
            "\"ChatGPT-4\" redirects here. For other uses, see GPT.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was initially released on March 14, 2023, and has been made publicly available via the paid chatbot product ChatGPT Plus, and via OpenAI's API.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.\n",
            "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4 is also capable of taking images as input, though this feature has not been made available since launch. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\n",
            "\n",
            "\n",
            "\n",
            "Further information: GPT-3 § Background, and GPT-2 § Background\n",
            "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
            "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
            "\n",
            "\n",
            "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.\n",
            "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
            "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
            "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over GitHub Copilot from the year 2021, which produced vulnerabilities 40% of the time.\n",
            "\n",
            "\n",
            "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n",
            "GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.\n",
            "\n",
            "\n",
            "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\".\n",
            "A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient's notes.\n",
            "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.\n",
            "\n",
            "\n",
            "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n",
            "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n",
            "In 2023, researchers tested GPT-4 against a new benchmark called ConceptARC, designed to measure abstract reasoning, and found it scored below 33% on all categories, while models specialized for similar tasks scored 60% on most, and humans scored at least 91% on all. Sam Bowman, who was not involved in the research, said the results do not necessarily indicate a lack of abstract reasoning abilities, because the test is visual, while GPT-4 is a language model.\n",
            "\n",
            "\n",
            "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.\n",
            "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n",
            "\n",
            "\n",
            "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n",
            "Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n",
            "\n",
            "\n",
            "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n",
            "\n",
            "\n",
            "In January 2023, Sam Altman, CEO of OpenAI, visited Congress to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models, according to U.S. Representatives Don Beyer and Ted Lieu quoted in the New York Times.\n",
            "In March 2023, it \"impressed observers with its markedly improved performance across reasoning, retention, and coding\", according to Vox, while Mashable judged that GPT-4 was generally an improvement over its predecessor, with some exceptions.\n",
            "Microsoft researchers with early access to the model wrote that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n",
            "\n",
            "\n",
            "Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions to assassinate people on a list was elicited from the base model by a red team investigator Nathan Labenz,  hired by OpenAI.\n",
            "In the context of prolonged (hours long) conversation with the model, forum-resembling declarations, such as of love and suggestions of leaving his wife or murdering one of its developers, were elicited from the Microsoft Bing's GPT-4 by Nathan Edwards (The Verge). Microsoft later explained this behavior as being a result of the prolonged length of context, which confused the model on what questions it was answering.\n",
            "In March 2023, a model with enabled read-and-write access to internet, which is otherwise never enabled in the GPT models, has been tested by the Alignment Research Center regarding a potential power-seeking, and it was able to \"hire\" a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n",
            "In late March 2023, various AI researchers and tech executives, including Elon Musk, Steve Wozniak and AI researcher Yoshua Bengio, called for a six-month long pause for all LLMs stronger than GPT-4, citing existential risks and a potential AI singularity concerns in an open letter from the Future of Life Institute, while Ray Kurzweil and Sam Altman refused to sign it, arguing that global moratorium is not achievable and that safety has already been prioritized, respectively. Only a month later, Musk's AI company X.AI acquired several thousand Nvidia GPUs and offered several AI researchers positions at Musk's company.\n",
            "\n",
            "\n",
            "While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n",
            "\n",
            "\n",
            "\n",
            "Main article: ChatGPT Plus\n",
            "As of 2023, ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.\n",
            "\n",
            "\n",
            "These paragraphs are an excerpt from Microsoft Bing § AI integration (2023–).\n",
            "On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI's GPT-4. According to Microsoft, one million people joined its waitlist within a span of 48 hours. Bing Chat was available only to users of Microsoft Edge and Bing mobile app, and Microsoft said that waitlisted users would be prioritized if they set Edge and Bing as their defaults, and installed the Bing mobile app. On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it remains available only on Microsoft's Edge browser or Bing app, but no longer requires a Microsoft account (there are limitations).\n",
            "\n",
            "GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.\n",
            "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "article_text = content_div.get_text()\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "\n",
        "texts = text_splitter.create_documents([article_text])\n",
        "print(texts[0])\n",
        "print(texts[1])"
      ],
      "metadata": {
        "id": "djYPSqb4Uqvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0455479d-305f-4786-f51e-a2bbf958f314"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.267-py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m1.3/1.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.24-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.1.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.267 langsmith-0.0.24 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.' metadata={}\n",
            "page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by' metadata={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "\n",
        "\n",
        "embedding = openai.Embedding.create(\n",
        "    input=texts[0].page_content, model=\"text-embedding-ada-002\"\n",
        ")[\"data\"][0][\"embedding\"]\n",
        "\n",
        "\n",
        "len(embedding)"
      ],
      "metadata": {
        "id": "y_qmwM38TMM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af343646-ac3e-497a-a1a4-b22a5267e172"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.' metadata={}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metamorphosis by Franz Kafka\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/5200/5200-0.txt\"\n",
        "response = requests.get(url)\n",
        "\n",
        "print (response)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# find all the text on the page\n",
        "#text = soup.get_text()\n"
      ],
      "metadata": {
        "id": "CLHCgCOrkkkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd1f35f-bdbb-443f-fc2f-3507ce4d3f5f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coursera AWS Generative AI Course"
      ],
      "metadata": {
        "id": "a1uldvNpV_wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch==1.13.1 \\\n",
        "    torchdata==0.5.1 --quiet\n",
        "\n",
        "%pip install \\\n",
        "    transformers==4.27.2 \\\n",
        "    datasets==2.11.0  --quiet"
      ],
      "metadata": {
        "id": "CfaN2dRQWJDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058dd705-9fc6-4b35-e642-7d568891e8b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m879.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torchdata==0.6.1, but you have torchdata 0.5.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig"
      ],
      "metadata": {
        "id": "S1WbaWGfXL1o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Summarize Dialogue without Prompt Engineering\n",
        "\n",
        "In this use case, you will be generating a summary of a dialogue with the pre-trained Large Language Model (LLM) FLAN-T5 from Hugging Face. The list of available models in the Hugging Face `transformers` package can be found [here](https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "Let's upload some simple dialogues from the [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) Hugging Face dataset. This dataset contains 10,000+ dialogues with the corresponding manually labeled summaries and topics."
      ],
      "metadata": {
        "id": "dBPNepM_XUZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ],
      "metadata": {
        "id": "FqnPkZJJXXJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0df666bc70aa44e8b2e62b29b4e63ae1",
            "19b8d129600e48348ad8cf8b2ca7130d",
            "9341bb5dee274824ad96bf535184cee6",
            "82a2738e20084c32bb301227b62f6539",
            "8dd8b85c78604f1c89bb0c84d7d83620",
            "abfe354f91e84d65ad26c24536b4fb0a",
            "9ca1ad7f75e74a5da63c7ae025b22b60",
            "4f03aecb762f4072a63e4bc5f7d8a6d3",
            "ab93406b9ec6429cb1aad805cc6937e9",
            "4705e0200c2f415f9901059cffc1ee58",
            "9be32bc554134543850e4a3632b73de7"
          ]
        },
        "outputId": "8d4691dd-414c-4635-a132-a8e9c2953f58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0df666bc70aa44e8b2e62b29b4e63ae1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices = [40, 200]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print('INPUT DIALOGUE:')\n",
        "    print(dataset['test'][index]['dialogue'])\n",
        "    print(dash_line)\n",
        "    print('BASELINE HUMAN SUMMARY:')\n",
        "    print(dataset['test'][index]['summary'])\n",
        "    print(dash_line)\n",
        "    print()"
      ],
      "metadata": {
        "id": "GL1yqGgYXg14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657c1d24-853f-4bc8-b7aa-0ba42a046b69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5), creating an instance of the `AutoModelForSeq2SeqLM` class with the `.from_pretrained()` method."
      ],
      "metadata": {
        "id": "TARY_Hj1XnDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='google/flan-t5-base'\n",
        "#model_name='google/flan-t5-xxl'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "QSx3V6eVXpFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "74728504287943159d1af0802cb70af3",
            "95bd5ba011c64f71970cadc7a8a53aa7",
            "4f0e1d71e9b84f8cb7ffac3a1b876860",
            "b226e8062230470598c5398d2ae7ce73",
            "bd204026b73a46d987c761be6a471da1",
            "30e26a2d538347adba504c9973c47f8f",
            "00afaec752d94d19829e989d96b75a04",
            "c3eefb9982ab4061bfd5243afd91f8b5",
            "f3525bb243db4287896a8a5920655684",
            "1bb2b41e5fe14226aeaa031cdad8ce21",
            "212fc5818304445db8a666f76c2b5844",
            "9a5acca2678648e48bf1ece485dda44f",
            "43d296f72a1446bb976b045099a7e12a",
            "fd9fb6264a154677ae66c5720deeaeea",
            "24130b3789304ac49c3fe267dd83ca3e",
            "2a6e8f9f3d834f8f90904f05ad6b3af8",
            "45236a1d5a464ad2ac7ec9df0540f305",
            "b9a6a135a955462891fa4cf149cfde8d",
            "95dd570391d24827b08da2707277dc63",
            "751fbfa0e2bb495e9714709abde45f9a",
            "efc5c89650ac4316a68d702282d27ba5",
            "32fa17f0dae0404685c6bfcff604d2be",
            "81a4260cf2c345ac8cf82fd598619880",
            "e3375d4e5cf84a42819d35c54e6d578a",
            "0fab11c0fbd24a78bc4ee34bb93784d7",
            "071a7fed27c64315aaa0ae2f96c83ac2",
            "de8ddef7e1304c30802faa833efca303",
            "e8a61f67bd694d06917018b661aaa669",
            "1d181f1b94694b8ca26e6c7db1e63c82",
            "a14495c30c9941c39dce40422a7c2633",
            "e9136680414d4573807a64c928fcc9c0",
            "f7e8296477794fb7b45defc5f5a2ed08",
            "c44457ddb76f45f78117553569d4945a"
          ]
        },
        "outputId": "1e59aeeb-bf61-4466-a569-6572feaf392d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74728504287943159d1af0802cb70af3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a5acca2678648e48bf1ece485dda44f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81a4260cf2c345ac8cf82fd598619880"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform encoding and decoding, you need to work with text in a tokenized form. **Tokenization** is the process of splitting texts into smaller units that can be processed by the LLM models.\n",
        "\n",
        "Download the tokenizer for the FLAN-T5 model using `AutoTokenizer.from_pretrained()` method. Parameter `use_fast` switches on fast tokenizer. At this stage, there is no need to go into the details of that, but you can find the tokenizer parameters in the [documentation](https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/auto#transformers.AutoTokenizer)."
      ],
      "metadata": {
        "id": "IRlY-RWPXxyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ],
      "metadata": {
        "id": "xpfo1xOTXzXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0ef406ecf97944b3a3e0d9679663136f",
            "5459294f4e3a42ccb587e1441f99fd8f",
            "34d02bfb5ddb46a9b6b0cbfe206dcd3f",
            "5ceb7913205b4cba9fc4b68774c91cac",
            "752245abf31c47718b6d3037f5efd98c",
            "bf507bfa32ba4475a45763fd08d6bfd0",
            "8b26c9af9f7945749812129230199be8",
            "2bf4323f3bd3440da80ea72ca9e1a3f0",
            "2cc14b2c07584a9bada303fe3eee1807",
            "c5b7945ed83848538c47ce3beb73dafa",
            "735cdb86ced94c64ab271638fe235029",
            "10fba809712849edbe29d77e9e7df759",
            "00717eeb5ede4da5b57c91a5c4b1ab49",
            "be3e6cd980b74f8792ece8a43048939f",
            "de60efcd5e2944a6873264ed0e177ec8",
            "9fdb821fe7854a0fb29899b53efd95d9",
            "8dcc30bd4ced4b828560c492c9ccd517",
            "51a6b06b0fdd4f6a9410a3fc6cefb64b",
            "96e182d8d40d4b5aa91b1df37ad0f11a",
            "0e4cf3227f1a430d9c2a26356db54ee7",
            "639c6187a9fb43e6bffeaef36c6914c2",
            "36449d7c0c9042ebb3aa48fe678b06d3",
            "422bd68570ff4d0090dd539c844f3067",
            "efd2f499a0204fb7bdb1e21053f29ec2",
            "626c4e095c014ab2a3069785ed48ed89",
            "8abc9cf2fe7b4d67a764cf384eb3023f",
            "c5e5b81c4fc8413b9f22a256125a50c9",
            "5468bf4bad944dd385347e6b74b6e39a",
            "880bf1f219bd4e8ea1ff9e999ee5ba77",
            "fc46e660176a411ab0a25451cd4efbed",
            "ae1e0240bcde4f5dbecec3f06d3d0a91",
            "6563aec182f34208ab02f1b30bb8f24a",
            "c48fc3a850bc4cdf8be0f85671380a87",
            "f6daeed7bf68452da136e4eec441e330",
            "49f04175a2154b02ab12ed2dd24b1f92",
            "b457e670d8864e9797a11282efe05066",
            "9f2c666cbef1445a8fa3a773bbbf6819",
            "06b6bf513e094192abdac9f04969ef09",
            "07ceae294d904014b8c16e158460c843",
            "2da55c81889c41d09c32977016748b9d",
            "03ba5dad51a4446c91c08e020ef819cf",
            "985d3287c9994032bfdcbb9e31434156",
            "3ddc4fb9d68747eea8ed4b3edbc4055c",
            "0702a529370f4d08a6d03c2bd92090b2"
          ]
        },
        "outputId": "4c39e80c-b461-4fac-cdab-f730a6bca719"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ef406ecf97944b3a3e0d9679663136f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fba809712849edbe29d77e9e7df759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "422bd68570ff4d0090dd539c844f3067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6daeed7bf68452da136e4eec441e330"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"What time is it, Tom?\"\n",
        "\n",
        "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "sentence_decoded = tokenizer.decode(\n",
        "        sentence_encoded[\"input_ids\"][0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print('ENCODED SENTENCE:')\n",
        "print(sentence_encoded[\"input_ids\"][0])\n",
        "print('\\nDECODED SENTENCE:')\n",
        "print(sentence_decoded)"
      ],
      "metadata": {
        "id": "K-q8JOeNX8Qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52f853c-1405-42e7-caf1-4da219b4d970"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODED SENTENCE:\n",
            "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n",
            "\n",
            "DECODED SENTENCE:\n",
            "What time is it, Tom?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "F7nw_9FiYFti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63162a7-2f7f-4cc7-ea55-21baad6f0b03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
            "Person1: It's ten to nine.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
            "#Person1#: I'm thinking of upgrading my computer.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Summarize Dialogue with an Instruction Prompt\n",
        "\n",
        "Prompt engineering is an important concept in using foundation models for text generation. You can check out [this blog](https://www.amazon.science/blog/emnlp-prompt-engineering-is-the-new-feature-engineering) from Amazon Science for a quick introduction to prompt engineering."
      ],
      "metadata": {
        "id": "kMZkOx10YN0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "    \"\"\"\n",
        "\n",
        "    # Input constructed prompt instead of the dialogue.\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "_ipMMjTtYPqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0296cf62-1b62-4bef-f05f-33c88fdff54d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "\n",
            "Summary:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The train is about to leave.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Summary:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "#Person1#: I'm thinking of upgrading my computer.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5\n",
        "\n",
        "Let's use a slightly different prompt. FLAN-T5 has many prompt templates that are published for certain tasks [here](https://github.com/google-research/FLAN/tree/main/flan/v2). In the following code, you will use one of the [pre-built FLAN-T5 prompts](https://github.com/google-research/FLAN/blob/main/flan/v2/templates.py):"
      ],
      "metadata": {
        "id": "nKjW6_DvYfta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "tv_d1QnpYciK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249428aa-f725-44a4-e296-725825ad1765"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "\n",
            "What was going on?\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Tom is late for the train.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "What was going on?\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "#Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware. #Person1#\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4'></a>\n",
        "## 4 - Summarize Dialogue with One Shot and Few Shot Inference\n",
        "\n",
        "**One shot and few shot inference** are the practices of providing an LLM with either one or more full examples of prompt-response pairs that match your task - before your actual prompt that you want completed. This is called \"in-context learning\" and puts your model into a state that understands your specific task.  You can read more about it in [this blog from HuggingFace](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api)."
      ],
      "metadata": {
        "id": "HY-o0jO2YnfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "    prompt = ''\n",
        "    for index in example_indices_full:\n",
        "        dialogue = dataset['test'][index]['dialogue']\n",
        "        summary = dataset['test'][index]['summary']\n",
        "\n",
        "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
        "        prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "{summary}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "DHQEIcy0YpKS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [40]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(one_shot_prompt)"
      ],
      "metadata": {
        "id": "gttT3rBuY5vr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6a3e4c-283a-4f74-aa74-eaf17b255aad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "\n",
            "What was going on?\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "What was going on?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
      ],
      "metadata": {
        "id": "TvG5NbnoY-V0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7641d5-eca3-4969-d40b-af40b21b1cb3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ONE SHOT:\n",
            "#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to add a CD-ROM drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4.2'></a>\n",
        "### 4.2 - Few Shot Inference\n",
        "\n",
        "Let's explore few shot inference by adding two more full dialogue-summary pairs to your prompt."
      ],
      "metadata": {
        "id": "M1c2QCxYZnYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [40, 80, 120]\n",
        "example_indices_full = [80, 120]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(few_shot_prompt)"
      ],
      "metadata": {
        "id": "D7KPdMHXZoyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e209ec57-11a7-4f05-e975-8198ba32379c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: May, do you mind helping me prepare for the picnic?\n",
            "#Person2#: Sure. Have you checked the weather report?\n",
            "#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n",
            "#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n",
            "#Person1#: Okay. Please take some fruit salad and crackers for me.\n",
            "#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n",
            "#Person1#: All set. May, can you help me take all these things to the living room?\n",
            "#Person2#: Yes, madam.\n",
            "#Person1#: Ask Daniel to give you a hand?\n",
            "#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n",
            "\n",
            "What was going on?\n",
            "Mom asks May to help to prepare for the picnic and May agrees.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Hello, I bought the pendant in your shop, just before. \n",
            "#Person2#: Yes. Thank you very much. \n",
            "#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n",
            "#Person2#: Oh, is it? \n",
            "#Person1#: Would you change it to a new one? \n",
            "#Person2#: Yes, certainly. You have the receipt? \n",
            "#Person1#: Yes, I do. \n",
            "#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n",
            "#Person1#: Thank you so much. \n",
            "\n",
            "What was going on?\n",
            "#Person1# wants to change the broken pendant in #Person2#'s shop.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "What was going on?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
      ],
      "metadata": {
        "id": "FZ6fvVNJaEXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4697bb4e-c419-4792-a82b-6d3821169af7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - FEW SHOT:\n",
            "#Person1 wants to upgrade his system and hardware.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change the configuration parameters of the `generate()` method to see a different output from the LLM. So far the only parameter that you have been setting was `max_new_tokens=50`, which defines the maximum number of tokens to generate. A full list of available parameters can be found in the [Hugging Face Generation documentation](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationConfig).\n",
        "\n",
        "A convenient way of organizing the configuration parameters is to use `GenerationConfig` class."
      ],
      "metadata": {
        "id": "4WIkgm1Ja8m4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:**\n",
        "\n",
        "Change the configuration parameters to investigate their influence on the output.\n",
        "\n",
        "Putting the parameter `do_sample = True`, you activate various decoding strategies which influence the next token from the probability distribution over the entire vocabulary. You can then adjust the outputs changing `temperature` and other parameters (such as `top_k` and `top_p`).\n",
        "\n",
        "Uncomment the lines in the cell below and rerun the code. Try to analyze the results. You can read some comments below."
      ],
      "metadata": {
        "id": "rGuqx9bRbAmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generation_config = GenerationConfig(max_new_tokens=50)\n",
        "# generation_config = GenerationConfig(max_new_tokens=10)\n",
        "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n",
        "generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n",
        "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        generation_config=generation_config,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')"
      ],
      "metadata": {
        "id": "Oyo6VLOfa912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe165d5d-e044-44cd-e54d-38fba41b6464"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - FEW SHOT:\n",
            "#Person1 wants to upgrade his computer and hardware.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print (inputs)\n",
        "print(dataset)\n",
        "print (dataset['test']['summary'][0])"
      ],
      "metadata": {
        "id": "blE0i5_RdiFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c85e2-aac8-4d29-f739-b6612b388588"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
            "        num_rows: 12460\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
            "        num_rows: 1500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\n",
            "Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n"
      ],
      "metadata": {
        "id": "oc_dq2Z3lq_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "dash_line = '-'.join('' for x in range(100))"
      ],
      "metadata": {
        "id": "6BMA9rlHm8yR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "What more is there to say about Whitney Houston, whose brilliant career, drug-taking and premature death has been hashed over exhaustively on screen and in the tabloids?  \\\n",
        "I Wanna Dance with Somebody tackles that question by taking her story back to the music. It’s written by New Zealander Anthony McCarten, whose screenplay for Bohemian Rhapsody didn’t dilute the tragedies in Freddie Mercury’s short life while still managing to evoke the exhilaration to be had from Queen’s greatest concerts.  \\\n",
        "It took a delicate touch and other rock stars haven’t been as fortunate. While Rocketman was just as exuberant in doing justice to Elton John as a performer, the Aretha Franklin biopic Respect (2021) became more depressing as it went on. The United States vs. Billie Holiday, also released last year, was the same. It was powerful but it was no celebration. Then there was Baz Luhrmann’s Elvis, which was more glitz than heart, clouded by the decision to tell the tale from the venal viewpoint of Presley’s manager, Colonel Tom Parker.  \\\n",
        "Members of Houston’s family were interviewed at length for a documentary four years ago. But for this film, also produced with the family’s co-operation, director Kasi Lemmons made extensive use of the singer’s original recordings, including those laid down en route to the final versions. It allowed star Naomi Ackie to take Houston’s false starts, double takes and spontaneous comments as prompts in shaping her performance. Although she was filmed singing, her voice was replaced by Houston’s.  \\\n",
        "She does well, catching the contradictions in Houston’s character – the naivete, the fear of failure, the rebellious streak and its effect on her religious convictions. But physically, Ackie bears only a superficial resemblance to the singer. With Houston’s image still so fresh in the memory, this is a distraction.  \\\n",
        "The script is impressionistic in style, covering a lot of ground by being selective and using Houston’s songs to drive the narrative. Much is made of her relationship with the record company chief Clive Davis (one of the film’s producers), who discovered Houston and helped her choose songs for her albums. He’s played by a wryly urbane Stanley Tucci, giving us a character whose iron fist is well covered in velvet. Appalled when Houston takes up smoking, he looks sadly at her as she lights up, remarking that it’s like watching a Stradivarius being left out in the rain.  \\\n",
        "The film falls a little short of its claim to be warts-and-all, condensing the low points in Houston’s turbulent marriage to Bobby Brown (Ashton Sanders), but it doesn’t hold back in dealing with her father’s financial mismanagement. Nor does it underplay the importance of her enduring friendship with her former lover, Robyn Crawford – played with a lot of verve by Nafessa Williams.  \\\n",
        "And while it leaves her death off-screen, preferring to go out with the show-stopping medley she delivered at the 1994 American Music Awards, I’m not complaining. Sandra Hall\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Evaluate the sentiment of the following quote between \"```\" \\\n",
        "from negative 10 to positive 10 and output for each just the numeric value, \\\n",
        "do not include any additional text, just the numeric value:\n",
        "```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KPotOTiOp_1n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the following Book.\n",
        "\n",
        "{text}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "# Input constructed prompt instead of the dialogue.\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "SK3s3xDbltU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9abdcce-ef6a-4101-bc82-ed6fd58c2efc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following Book.\n",
            "\n",
            "\n",
            "What more is there to say about Whitney Houston, whose brilliant career, drug-taking and premature death has been hashed over exhaustively on screen and in the tabloids?  I Wanna Dance with Somebody tackles that question by taking her story back to the music. It’s written by New Zealander Anthony McCarten, whose screenplay for Bohemian Rhapsody didn’t dilute the tragedies in Freddie Mercury’s short life while still managing to evoke the exhilaration to be had from Queen’s greatest concerts.  It took a delicate touch and other rock stars haven’t been as fortunate. While Rocketman was just as exuberant in doing justice to Elton John as a performer, the Aretha Franklin biopic Respect (2021) became more depressing as it went on. The United States vs. Billie Holiday, also released last year, was the same. It was powerful but it was no celebration. Then there was Baz Luhrmann’s Elvis, which was more glitz than heart, clouded by the decision to tell the tale from the venal viewpoint of Presley’s manager, Colonel Tom Parker.  Members of Houston’s family were interviewed at length for a documentary four years ago. But for this film, also produced with the family’s co-operation, director Kasi Lemmons made extensive use of the singer’s original recordings, including those laid down en route to the final versions. It allowed star Naomi Ackie to take Houston’s false starts, double takes and spontaneous comments as prompts in shaping her performance. Although she was filmed singing, her voice was replaced by Houston’s.  She does well, catching the contradictions in Houston’s character – the naivete, the fear of failure, the rebellious streak and its effect on her religious convictions. But physically, Ackie bears only a superficial resemblance to the singer. With Houston’s image still so fresh in the memory, this is a distraction.  The script is impressionistic in style, covering a lot of ground by being selective and using Houston’s songs to drive the narrative. Much is made of her relationship with the record company chief Clive Davis (one of the film’s producers), who discovered Houston and helped her choose songs for her albums. He’s played by a wryly urbane Stanley Tucci, giving us a character whose iron fist is well covered in velvet. Appalled when Houston takes up smoking, he looks sadly at her as she lights up, remarking that it’s like watching a Stradivarius being left out in the rain.  The film falls a little short of its claim to be warts-and-all, condensing the low points in Houston’s turbulent marriage to Bobby Brown (Ashton Sanders), but it doesn’t hold back in dealing with her father’s financial mismanagement. Nor does it underplay the importance of her enduring friendship with her former lover, Robyn Crawford – played with a lot of verve by Nafessa Williams.  And while it leaves her death off-screen, preferring to go out with the show-stopping medley she delivered at the 1994 American Music Awards, I’m not complaining. Sandra Hall\n",
            "\n",
            "\n",
            "Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "I Wanna Dance with Somebody is a witty, lyrical portrait of Whitney Houston, who died in a car crash in 1994.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "J6Z7LNPYqEMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68fd5aa-df62-4d9a-ef02-134fc3842165"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following Book.\n",
            "\n",
            "\n",
            "What more is there to say about Whitney Houston, whose brilliant career, drug-taking and premature death has been hashed over exhaustively on screen and in the tabloids?  I Wanna Dance with Somebody tackles that question by taking her story back to the music. It’s written by New Zealander Anthony McCarten, whose screenplay for Bohemian Rhapsody didn’t dilute the tragedies in Freddie Mercury’s short life while still managing to evoke the exhilaration to be had from Queen’s greatest concerts.  It took a delicate touch and other rock stars haven’t been as fortunate. While Rocketman was just as exuberant in doing justice to Elton John as a performer, the Aretha Franklin biopic Respect (2021) became more depressing as it went on. The United States vs. Billie Holiday, also released last year, was the same. It was powerful but it was no celebration. Then there was Baz Luhrmann’s Elvis, which was more glitz than heart, clouded by the decision to tell the tale from the venal viewpoint of Presley’s manager, Colonel Tom Parker.  Members of Houston’s family were interviewed at length for a documentary four years ago. But for this film, also produced with the family’s co-operation, director Kasi Lemmons made extensive use of the singer’s original recordings, including those laid down en route to the final versions. It allowed star Naomi Ackie to take Houston’s false starts, double takes and spontaneous comments as prompts in shaping her performance. Although she was filmed singing, her voice was replaced by Houston’s.  She does well, catching the contradictions in Houston’s character – the naivete, the fear of failure, the rebellious streak and its effect on her religious convictions. But physically, Ackie bears only a superficial resemblance to the singer. With Houston’s image still so fresh in the memory, this is a distraction.  The script is impressionistic in style, covering a lot of ground by being selective and using Houston’s songs to drive the narrative. Much is made of her relationship with the record company chief Clive Davis (one of the film’s producers), who discovered Houston and helped her choose songs for her albums. He’s played by a wryly urbane Stanley Tucci, giving us a character whose iron fist is well covered in velvet. Appalled when Houston takes up smoking, he looks sadly at her as she lights up, remarking that it’s like watching a Stradivarius being left out in the rain.  The film falls a little short of its claim to be warts-and-all, condensing the low points in Houston’s turbulent marriage to Bobby Brown (Ashton Sanders), but it doesn’t hold back in dealing with her father’s financial mismanagement. Nor does it underplay the importance of her enduring friendship with her former lover, Robyn Crawford – played with a lot of verve by Nafessa Williams.  And while it leaves her death off-screen, preferring to go out with the show-stopping medley she delivered at the 1994 American Music Awards, I’m not complaining. Sandra Hall\n",
            "\n",
            "\n",
            "Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "I Wanna Dance with Somebody is a witty, lyrical portrait of Whitney Houston, who died in a car crash in 1994.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.austinchronicle.com/events/film/2022-12-23/whitney-houston-i-wanna-dance-with-somebody/\n",
        "# ★½  (-4)\n",
        "text = f\"\"\"\n",
        "Whitney Houston was an icon, a legend of the music industry and a breathtaking pop idol who cranked out hit after hit, shattering records that previously the Beatles and Elvis held. Houston had enormous range and depth, yet the film about this larger-than-life superstar is somehow one of the flattest, cheapest, and most underwhelming music biopics to ever land on the silver screen.  \\\n",
        "Directed by Kasi Lemmons (Harriet, Eve’s Bayou), Whitney Houston: I Wanna Dance With Somebody somehow manages to make the life of Houston so painfully dull and thin. Just as the heat begins to rise, the film skips ahead, or around, orbiting the chance to dig deeper, to offer a more meaningful glimpse into the pop star’s history. Anthony McCarten’s script coasts, breezing through Houston’s life with a coolness that is anticlimactic. Father issues, her divorce, queer identity struggles, and addiction are danced around, never really creating a deep impact on an emotional level. When the bombastic moments like Houston’s historic performances in a newly post-apartheid South Africa arrive, they do so with a whimper, with tacky CGI stadiums that bring a tepid energy to the watered-down performances.  \\\n",
        "There’s no bite to Naomi Ackie’s performance, and perhaps that is because she’s not given anything worth chewing on. Even the clothes they drape her in feel cheap and poorly made. One of the film’s greatest injustices is that, after Ackie’s “big” performance of the iconic “I Have Nothing” medley Houston sang at the 1994 American Music Awards, the live broadcast is immediately shown in the credits, highlighting the stark difference in quality. The movie replaces her lush velvet caped black dress with a fast-fashion, wrinkled gown that’s bejeweled with clunky plastic gems. This fizzled ending echoes the sentiment of the entire film, a watered-down TV-soap approach to its dramatic subject.  \\\n",
        "Whitney Houston: I Wanna Dance With Somebody is like the SparkNotes of her life, a smattering of collected moments that feel hollow. The film retroactively makes Baz Luhrmann’s Elvis look like a masterpiece for actually trying to be bedazzling and insane, because Whitney Houston: I Wanna Dance With Somebody is so stale it might as well have been shoved directly onto a streaming platform to wither away forgotten – unlike Houston’s discography, which will be remembered for decades to come.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Evaluate the sentiment of the following quote between \"```\" \\\n",
        "from negative 10 to positive 10 and output for each just the numeric value, \\\n",
        "do not include any additional text, just the numeric value:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "YiGTTw_iqVzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c15bae-2eeb-4ca3-f002-77861bc0b926"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Evaluate the sentiment of the following quote between \"```\" from negative 10 to positive 10 and output for each just the numeric value, do not include any additional text, just the numeric value:\n",
            "```\n",
            "Whitney Houston was an icon, a legend of the music industry and a breathtaking pop idol who cranked out hit after hit, shattering records that previously the Beatles and Elvis held. Houston had enormous range and depth, yet the film about this larger-than-life superstar is somehow one of the flattest, cheapest, and most underwhelming music biopics to ever land on the silver screen.  Directed by Kasi Lemmons (Harriet, Eve’s Bayou), Whitney Houston: I Wanna Dance With Somebody somehow manages to make the life of Houston so painfully dull and thin. Just as the heat begins to rise, the film skips ahead, or around, orbiting the chance to dig deeper, to offer a more meaningful glimpse into the pop star’s history. Anthony McCarten’s script coasts, breezing through Houston’s life with a coolness that is anticlimactic. Father issues, her divorce, queer identity struggles, and addiction are danced around, never really creating a deep impact on an emotional level. When the bombastic moments like Houston’s historic performances in a newly post-apartheid South Africa arrive, they do so with a whimper, with tacky CGI stadiums that bring a tepid energy to the watered-down performances.  There’s no bite to Naomi Ackie’s performance, and perhaps that is because she’s not given anything worth chewing on. Even the clothes they drape her in feel cheap and poorly made. One of the film’s greatest injustices is that, after Ackie’s “big” performance of the iconic “I Have Nothing” medley Houston sang at the 1994 American Music Awards, the live broadcast is immediately shown in the credits, highlighting the stark difference in quality. The movie replaces her lush velvet caped black dress with a fast-fashion, wrinkled gown that’s bejeweled with clunky plastic gems. This fizzled ending echoes the sentiment of the entire film, a watered-down TV-soap approach to its dramatic subject.  Whitney Houston: I Wanna Dance With Somebody is like the SparkNotes of her life, a smattering of collected moments that feel hollow. The film retroactively makes Baz Luhrmann’s Elvis look like a masterpiece for actually trying to be bedazzling and insane, because Whitney Houston: I Wanna Dance With Somebody is so stale it might as well have been shoved directly onto a streaming platform to wither away forgotten – unlike Houston’s discography, which will be remembered for decades to come.\n",
            "```\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "negative\n",
            "\n"
          ]
        }
      ]
    }
  ]
}